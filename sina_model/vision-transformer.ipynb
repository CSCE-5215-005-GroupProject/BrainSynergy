{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1980, 2),\n",
       "           image  label\n",
       " 918   G_350.jpg      1\n",
       " 708   M_655.jpg      2\n",
       " 940   M_721.jpg      2\n",
       " 360   M_580.jpg      2\n",
       " 1272   M_36.jpg      2\n",
       " 355    G_43.jpg      1\n",
       " 959   M_785.jpg      2\n",
       " 1464   M_20.jpg      2\n",
       " 1618   G_23.jpg      1\n",
       " 2338  M_531.jpg      2\n",
       " 884     N_8.jpg      0\n",
       " 1913  G_389.jpg      1\n",
       " 205   M_722.jpg      2\n",
       " 102   M_253.jpg      2\n",
       " 159   G_835.jpg      1\n",
       " 1197  P_199.jpg      3\n",
       " 108   M_160.jpg      2\n",
       " 1349  N_273.jpg      0\n",
       " 1765  M_197.jpg      2\n",
       " 1329  M_578.jpg      2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Create a DataFrame to store file paths and labels\n",
    "df = pd.DataFrame(columns=['image', 'label'])\n",
    "\n",
    "# Read images from the directory and assign labels based on file prefixes\n",
    "for filename in os.listdir('./data/competition_data'):\n",
    "    if filename.startswith('G_'):\n",
    "        label = 'glioma_tumor'\n",
    "    elif filename.startswith('M_'):\n",
    "        label = 'meningioma_tumor'\n",
    "    elif filename.startswith('P_'):\n",
    "        label = 'pituitary_tumor'\n",
    "    elif filename.startswith('N_'):\n",
    "        label = 'normal'\n",
    "    else:\n",
    "        continue  # Skip files that don't match the pattern\n",
    "    df = df.append({'image': filename, 'label': label}, ignore_index=True)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df = shuffle(df)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "df_train, df_non_train = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_validation, df_test = train_test_split(df_non_train, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert labels to numeric \n",
    "label2id = {'normal': 0, 'glioma_tumor': 1,\n",
    "            'meningioma_tumor': 2, 'pituitary_tumor': 3}\n",
    "id2label = {0: 'normal', 1: 'glioma_tumor',\n",
    "            2: 'meningioma_tumor', 3: 'pituitary_tumor'}\n",
    "df_train['label'] = df_train['label'].map(label2id)\n",
    "df_validation['label'] = df_validation['label'].map(label2id)\n",
    "df_test['label'] = df_test['label'].map(label2id)\n",
    "\n",
    "# Display the shape and first 20 rows of the training DataFrame\n",
    "df_train.shape, df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>M_219.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  label\n",
       "138  M_219.jpg      2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log where image name is M_219.jpg\n",
    "df_train[df_train['image'] == 'M_219.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the transformer dataset and the model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTModel, ViTConfig\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from PIL import Image  # Importing the Image class\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        self.resize = transforms.Resize((224, 224))\n",
    "        self.ToTensor = transforms.ToTensor()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base_path = \"./data/competition_data/\"\n",
    "        filename = self.df.iloc[idx, 0]\n",
    "        full_img_path = os.path.join(base_path, filename)\n",
    "        raw_image = Image.open(full_img_path)\n",
    "        image = self.resize(raw_image)\n",
    "        image = self.ToTensor(image)\n",
    "        label = self.df.iloc[idx, 1]  # Adjust this if necessary\n",
    "        return image, label\n",
    "\n",
    "class ViTForImageClassification(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(ViTForImageClassification, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained(\n",
    "            'google/vit-base-patch16-224-in21k', add_pooling_layer=False)\n",
    "        self.classifier = nn.Linear(self.vit.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vit(x)['last_hidden_state']\n",
    "        x = self.classifier(x[:, 0, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train the model on the train dataset and use the validation dataset to calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize dataset and dataloader\n",
    "train_dataset = BrainTumorDataset(df_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "validation_dataset = BrainTumorDataset(df_validation)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "def evaluate_model(model, validation_dataloader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    avg_loss = val_loss / len(validation_dataloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = ViTForImageClassification(num_labels=len(label2id))\n",
    "model = model.to(device)\n",
    "\n",
    "# Training loop\n",
    "optimizer = Adam(model.parameters(), lr=1e-6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "for epoch in range(500):  # Maximum number of epochs\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(train_dataloader):\n",
    "        labels = labels.to(device)\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    validation_loss, validation_accuracy = evaluate_model(model, validation_dataloader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {total_loss / len(train_dataloader)}, Validation Loss: {validation_loss}, Validation Accuracy: {validation_accuracy}\")\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n",
    "\n",
    "    # Ask if continue training\n",
    "    if validation_accuracy > 0.95:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTModel: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 248/248 [00:02<00:00, 104.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9919354838709677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = ViTForImageClassification(num_labels=len(label2id))\n",
    "model.load_state_dict(torch.load('model_epoch_58.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "# use the trained model to predict on the validation set\n",
    "model.eval()\n",
    "dataset = BrainTumorDataset(df_test)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(dataloader):\n",
    "        labels = labels.to(device)\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += 1\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Accuracy: {correct / total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the model on the kaggle dataset and get the labels for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 621/621 [00:06<00:00, 98.77it/s]\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "df = pd.DataFrame(columns=['image', 'label'])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "possible_labels = ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor', 'normal']\n",
    "\n",
    "# Read images from the directory and assign labels based on file prefixes\n",
    "# if the TA is going to run this then please change the path to the kaggle_solutionSet in the first cell and and also in the dataloader\n",
    "# it will not work if the path is not changed\n",
    "for filename in os.listdir('./data/kaggle_solutionSet'):\n",
    "    label = 'unknown'\n",
    "    df = df.append({'image': filename, 'label': label}, ignore_index=True)\n",
    "\n",
    "label2id = {'normal': 0, 'glioma_tumor': 1, 'meningioma_tumor': 2, 'pituitary_tumor': 3}\n",
    "id2label = {0: 'normal', 1: 'glioma_tumor', 2: 'meningioma_tumor', 3: 'pituitary_tumor'}\n",
    "\n",
    "model = ViTForImageClassification(num_labels=len(label2id))\n",
    "model.load_state_dict(torch.load('model_epoch_58.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Data loader\n",
    "result_dataset = BrainTumorDataset(df)\n",
    "result_dataloader = DataLoader(result_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "df_result = pd.DataFrame(columns=['ID', 'prediction'])\n",
    "\n",
    "# Predict and save labels\n",
    "for i, (images, _) in enumerate(tqdm(result_dataloader)):\n",
    "    images = images.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    label_id = predicted.item()\n",
    "    label_name = id2label[label_id]\n",
    "    df_result.at[i, 'prediction'] = label_name\n",
    "    df_result.at[i, 'ID'] = df.iloc[i, 0]\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df_result.to_csv('predicted_labels.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
