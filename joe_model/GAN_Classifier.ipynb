{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zQggq2qu0Xb-",
        "outputId": "6902da65-1e4b-44d3-9d89-f0ff07d9714f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.14.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check TensorFlow version\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "assert \"2.\" in tf.__version__, \"This notebook is designed to run on TensorFlow 2.x\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional imports here\n",
        "import os\n",
        "from tensorflow.keras import layers, regularizers"
      ],
      "metadata": {
        "id": "hX1J-4P7FeHh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive for data access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MQOpxbiy10zq",
        "outputId": "06b7f64a-4045-4275-a0e5-c7cb2cc6fd8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize directories\n",
        "gan_data_dir = '/content/drive/My Drive/ML-GroupProject/Processed_Data/GAN_Training'\n",
        "\n",
        "classifier_train_dir = '/content/drive/My Drive/ML-GroupProject/Processed_Data/Classifier_Training'\n",
        "\n",
        "classifier_test_dir = '/content/drive/My Drive/ML-GroupProject/Processed_Data/Classifier_Testing'"
      ],
      "metadata": {
        "id": "MoCL5SnzFjvH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset for GAN Training\n",
        "\n",
        "batch_size = 32  # Adjust as needed\n",
        "\n",
        "# Function to normalize images\n",
        "def normalize_image(image):\n",
        "    # Normalize the images to [-1, 1]\n",
        "    image = (image - 127.5) / 127.5\n",
        "    return image\n",
        "\n",
        "# Load the dataset\n",
        "gan_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    gan_data_dir,\n",
        "    label_mode=None,  # No labels needed as this is unsupervised learning\n",
        "    image_size=(256, 256),  # Images are already of this size\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ").map(normalize_image).cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "YqcyJ2t9Fwcg",
        "outputId": "19e4b9bb-8504-46d7-ad9d-75accc48d854",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3464 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions for layer definitions\n",
        "# This will help with testing different achitectures\n",
        "\n",
        "# Regularization weight-    *might need to tune this value\n",
        "l2_weight = 0.000025\n",
        "\n",
        "# Dense layer\n",
        "def dense(inputs, units):\n",
        "    return layers.Dense(\n",
        "        units, activation=None,\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        kernel_regularizer=regularizers.l2(l2_weight),\n",
        "        bias_regularizer=regularizers.l2(l2_weight))(inputs)\n",
        "\n",
        "# Batch normalization layer\n",
        "def batch_norm(inputs, is_training=True):\n",
        "    return layers.BatchNormalization(momentum=0.999, epsilon=0.001)(inputs, training=is_training)\n",
        "\n",
        "# Convolutional layer\n",
        "def conv2d(inputs, filters, kernel_size, stride):\n",
        "    return layers.Conv2D(\n",
        "        filters, kernel_size, strides=stride, activation=None, padding='same',\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        kernel_regularizer=regularizers.l2(l2_weight),\n",
        "        bias_regularizer=regularizers.l2(l2_weight))(inputs)\n",
        "\n",
        "# Transposed convolutional layer (deconvolutional layer)\n",
        "def deconv2d(inputs, filters, kernel_size, stride):\n",
        "    return layers.Conv2DTranspose(\n",
        "        filters, kernel_size, strides=stride, activation='relu', padding='same',\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        kernel_regularizer=regularizers.l2(l2_weight),\n",
        "        bias_regularizer=regularizers.l2(l2_weight))(inputs)"
      ],
      "metadata": {
        "id": "vDlkGySYLLud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Generator architecture\n",
        "\n",
        "def make_generator_model(noise_dim, is_training=True, l2_weight):\n",
        "    # Input: Noise vector\n",
        "    noise = layers.Input(shape=(noise_dim,))\n",
        "\n",
        "    # First dense layer\n",
        "    net = dense(noise, 8*8*256)                 # 8*8 represents spatial dims of feature map, 256 number of channels (depth) of feature map\n",
        "    net = batch_norm(net, is_training)\n",
        "    net = layers.LeakyReLU()(net)\n",
        "\n",
        "    # Reshape to start the convolutional stack\n",
        "    net = layers.Reshape((8, 8, 256))(net)\n",
        "\n",
        "    # Deconvolutional layers: stride (1,1) so spatial dims is 8x8, 128 is the number of filters (depth)\n",
        "    net = deconv2d(net, 128, (5, 5), (1, 1), weight_decay)\n",
        "    net = batch_norm(net, is_training)\n",
        "    net = layers.LeakyReLU()(net)\n",
        "\n",
        "    # Upscale to 16x16:   Stride (2,2)\n",
        "    net = deconv2d(net, 64, (5, 5), (2, 2), weight_decay)\n",
        "    net = batch_norm(net, is_training)\n",
        "    net = layers.LeakyReLU()(net)\n",
        "\n",
        "    # Upscale to 32x32:   Stride (2,2)\n",
        "    net = deconv2d(net, 32, (5,5), (2,2), weight_decay)\n",
        "    net = batch_norm(net, is_training)\n",
        "    net = layers.LeakyReLU()(net)\n",
        "\n",
        "    # Upscale to 64x64:   Stride (2,2)\n",
        "    net = deconv2d(net, 16, (5,5), (2,2), weight_decay)\n",
        "    net = batch_norm(net, is_training)\n",
        "    net = layers.LeakyReLU()(net)\n",
        "\n",
        "    # Final deconvolutional layer: Upscale to 256x256: Stride (4,4) with 1 filter for greyscale output (if RGB, change 1 to 3)\n",
        "    net = deconv2d(net, 1, (5, 5), (4, 4), weight_decay)\n",
        "    net = layers.Activation('tanh')(net)  # Outputs in [-1, 1]\n",
        "\n",
        "    # Create the Keras model\n",
        "    return tf.keras.Model(inputs=noise, outputs=net)\n"
      ],
      "metadata": {
        "id": "HHVg9HytM-Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Discriminator architecture   ##### STILL WORKING ON THIS!!!  #####\n",
        "\n",
        "def make_discriminator_model(is_training=True, l2_weight):\n",
        "    # Input: Image\n",
        "    input_image = layers.Input(shape=(256, 256, 1))  # Update the shape for grayscale images\n",
        "\n",
        "    # Convolutional layers: stride (2,2) to downsample the image\n",
        "    net = conv2d(input_image, 64, (5, 5), (2, 2), l2_weight)\n",
        "    net = layers.LeakyReLU()(net)\n",
        "    net = layers.Dropout(0.3)(net, training=is_training)\n",
        "\n",
        "    net = conv2d(net, 128, (5, 5), (2, 2), l2_weight)\n",
        "    net = layers.LeakyReLU()(net)\n",
        "    net = layers.Dropout(0.3)(net, training=is_training)\n",
        "\n",
        "    # Continue adding more layers if needed...\n",
        "\n",
        "    # Flatten and final dense layer\n",
        "    net = layers.Flatten()(net)\n",
        "    net = dense(net, 1)  # Output layer with a single neuron for binary classification\n",
        "\n",
        "    # Create the Keras model\n",
        "    return tf.keras.Model(inputs=input_image, outputs=net)\n"
      ],
      "metadata": {
        "id": "Lcm6mYhHTiLW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}